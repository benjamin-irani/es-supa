import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.57.4';
const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type'
};
serve(async (req)=>{
  if (req.method === 'OPTIONS') {
    return new Response(null, {
      headers: corsHeaders
    });
  }
  try {
    const requestBody = await req.json();
    console.log('üì• Received request:', JSON.stringify(requestBody, null, 2));
    const { action, sourceUrl, sourceKey, targetUrl, targetKey, supabaseUrl, supabaseKey, serviceRoleKey, migrationSql, options = {} } = requestBody;
    // Handle parameter variations from different calling patterns
    const finalTargetUrl = targetUrl || supabaseUrl;
    const finalTargetKey = serviceRoleKey || targetKey || supabaseKey;
    console.log('üîç Processing parameters:', {
      action,
      finalTargetUrl: finalTargetUrl ? 'provided' : 'missing',
      finalTargetKey: finalTargetKey ? 'provided' : 'missing',
      hasServiceRoleKey: !!serviceRoleKey,
      hasMigrationSql: !!migrationSql
    });
    if (!finalTargetUrl || !finalTargetKey) {
      throw new Error(`Missing required parameters: targetUrl/supabaseUrl and targetKey/supabaseKey are required`);
    }
    console.log(`Enhanced Schema Cloner: Processing action ${action} for target ${extractProjectId(finalTargetUrl)}`);
    // Create target client
    const targetClient = createClient(finalTargetUrl, finalTargetKey);
    // Create source client with fallback to current project
    let sourceClient = null;
    const currentProjectUrl = "https://uezenrqnuuaglgwnvbsx.supabase.co";
    const currentProjectKey = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InVlemVucnFudXVhZ2xnd252YnN4Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDYyNzYyMzQsImV4cCI6MjA2MTg1MjIzNH0.DbkOgj_rI5nb4FukNUtEl-ij2Rqz2V4RVI9JvEx58KU";
    if ([
      'sync-schema',
      'migrate-data',
      'verify-clone'
    ].includes(action)) {
      const finalSourceUrl = sourceUrl || currentProjectUrl;
      const finalSourceKey = sourceKey || currentProjectKey;
      sourceClient = createClient(finalSourceUrl, finalSourceKey);
      console.log(`üì° Source client created for ${extractProjectId(finalSourceUrl)}`);
    }
    let result;
    switch(action){
      case 'migrate-data':
        result = await migrateDataSafe(sourceClient, targetClient, options);
        break;
      case 'verify-clone':
        result = await verifyClone(sourceClient, targetClient);
        break;
      case 'deploy-schema':
        result = await deploySchema(targetClient, {
          ...options,
          migrationSql,
          serviceRoleKey
        });
        break;
      case 'setup-storage':
        result = await setupStorage(targetClient, options);
        break;
      case 'fresh-install-cleanup':
        result = await executeFreshInstallCleanup(targetClient, options);
        break;
      case 'execute-step':
        result = await executeUpgradeStep(targetClient, options);
        break;
      case 'create-backup':
        result = await createBackup(targetClient, options);
        break;
      case 'execute-rollback':
        result = await executeRollback(targetClient, options);
        break;
      default:
        throw new Error(`Unknown action: ${action}`);
    }
    return new Response(JSON.stringify({
      success: true,
      data: result
    }), {
      headers: {
        ...corsHeaders,
        'Content-Type': 'application/json'
      }
    });
  } catch (error) {
    console.error('Enhanced Schema Cloner error:', error);
    return new Response(JSON.stringify({
      success: false,
      error: error.message,
      timestamp: new Date().toISOString()
    }), {
      status: 500,
      headers: {
        ...corsHeaders,
        'Content-Type': 'application/json'
      }
    });
  }
});
// Safe data migration with improved logic
async function migrateDataSafe(sourceClient, targetClient, options) {
  console.log('üìä Starting improved data migration...');
  const results = {
    processedTables: 0,
    totalRecords: 0,
    migratedRecords: 0,
    errors: []
  };
  try {
    // Get tables using safe RPC
    const { data: sourceTables, error: sourceError } = await sourceClient.rpc('list_public_tables');
    const { data: targetTables, error: targetError } = await targetClient.rpc('list_public_tables');
    if (sourceError || targetError) {
      console.log('‚ö†Ô∏è RPC not available, using fallback table list');
      return await fallbackMigration(sourceClient, targetClient);
    }
    const targetTableNames = new Set(targetTables.map((t)=>t.table_name));
    console.log(`üìä Source: ${sourceTables.length} tables, Target: ${targetTables.length} tables`);
    for (const table of sourceTables){
      const tableName = table.table_name;
      if (!targetTableNames.has(tableName)) {
        console.log(`‚è≠Ô∏è Skipping ${tableName} - not in target`);
        continue;
      }
      try {
        // Check if table has id primary key
        const { data: hasIdPk } = await targetClient.rpc('table_has_id_pk', {
          p_table_name: tableName
        });
        if (!hasIdPk) {
          console.log(`‚è≠Ô∏è Skipping ${tableName} - no id primary key`);
          continue;
        }
        // Get data from source
        const { data: sourceData, error: readError } = await sourceClient.from(tableName).select('*');
        if (readError || !sourceData || sourceData.length === 0) {
          console.log(`üì≠ ${tableName} is empty or unreadable`);
          continue;
        }
        console.log(`üìä Migrating ${sourceData.length} records from ${tableName}`);
        results.totalRecords += sourceData.length;
        // Migrate in batches
        const batchSize = 50;
        let migratedCount = 0;
        for(let i = 0; i < sourceData.length; i += batchSize){
          const batch = sourceData.slice(i, i + batchSize);
          const { error: upsertError } = await targetClient.from(tableName).upsert(batch, {
            onConflict: 'id',
            ignoreDuplicates: false
          });
          if (!upsertError) {
            migratedCount += batch.length;
          } else {
            console.log(`‚ö†Ô∏è Batch failed for ${tableName}: ${upsertError.message}`);
          }
        }
        if (migratedCount > 0) {
          results.migratedRecords += migratedCount;
          results.processedTables++;
          console.log(`‚úÖ ${tableName}: ${migratedCount}/${sourceData.length} records`);
        }
      } catch (tableError) {
        console.log(`‚ùå Error with ${tableName}: ${tableError.message}`);
        results.errors.push(`${tableName}: ${tableError.message}`);
      }
    }
  } catch (globalError) {
    console.error('‚ùå Global migration error:', globalError);
    results.errors.push(`Global error: ${globalError.message}`);
  }
  console.log(`üéâ Migration completed: ${results.migratedRecords} records from ${results.processedTables} tables`);
  return {
    success: results.migratedRecords > 0,
    message: `Migration completed: ${results.migratedRecords} records from ${results.processedTables} tables`,
    ...results
  };
}
// Fallback migration for when RPCs are not available
async function fallbackMigration(sourceClient, targetClient) {
  console.log('üìä Running fallback migration...');
  const essentialTables = [
    'site_settings',
    'site_categories',
    'articles',
    'events',
    'projects'
  ];
  let totalMigrated = 0;
  for (const tableName of essentialTables){
    try {
      const { data: sourceData } = await sourceClient.from(tableName).select('*');
      if (sourceData && sourceData.length > 0) {
        const { error } = await targetClient.from(tableName).upsert(sourceData, {
          onConflict: 'id',
          ignoreDuplicates: false
        });
        if (!error) {
          totalMigrated += sourceData.length;
          console.log(`‚úÖ ${tableName}: ${sourceData.length} records`);
        }
      }
    } catch (error) {
      console.log(`‚ö†Ô∏è ${tableName} migration failed`);
    }
  }
  return {
    success: totalMigrated > 0,
    message: `Fallback migration: ${totalMigrated} records`,
    migratedRecords: totalMigrated,
    processedTables: essentialTables.length
  };
}
// Simplified verification
async function verifyClone(sourceClient, targetClient) {
  console.log('üîç Verifying clone...');
  const verification = {
    matchingTables: 0,
    totalChecked: 0,
    issues: []
  };
  try {
    const { data: targetTables } = await targetClient.rpc('list_public_tables');
    if (!targetTables) {
      return {
        success: false,
        message: 'Could not verify - RPC not available'
      };
    }
    for (const table of targetTables.slice(0, 10)){
      const tableName = table.table_name;
      verification.totalChecked++;
      try {
        const { data: targetCount } = await targetClient.rpc('get_table_count', {
          p_table_name: tableName
        });
        if (targetCount > 0) {
          verification.matchingTables++;
          console.log(`‚úÖ ${tableName}: ${targetCount} rows`);
        }
      } catch (error) {
        verification.issues.push(`${tableName}: verification failed`);
      }
    }
    const completionPercentage = Math.round(verification.matchingTables / verification.totalChecked * 100);
    return {
      success: verification.matchingTables > 0,
      message: `Verification: ${verification.matchingTables}/${verification.totalChecked} tables (${completionPercentage}%)`,
      ...verification,
      completionPercentage
    };
  } catch (error) {
    return {
      success: false,
      message: `Verification failed: ${error.message}`,
      ...verification
    };
  }
}
// Schema deployment
async function deploySchema(targetClient, options) {
  console.log('üöÄ Starting schema deployment...');
  const { migrationSql } = options;
  if (!migrationSql) {
    return {
      success: false,
      requiresManualDeployment: true,
      message: 'Manual deployment required - no migration SQL provided'
    };
  }
  try {
    console.log('üìù Executing migration SQL...');
    // Split SQL into statements and execute them
    const statements = migrationSql.split(';').map((s)=>s.trim()).filter((s)=>s.length > 0);
    console.log(`Found ${statements.length} SQL statements to execute`);
    for(let i = 0; i < statements.length; i++){
      const statement = statements[i];
      console.log(`Executing statement ${i + 1}/${statements.length}: ${statement.substring(0, 100)}...`);
      const { error } = await targetClient.rpc('exec_sql', {
        sql: statement
      });
      if (error) {
        console.log(`‚ö†Ô∏è Statement ${i + 1} failed: ${error.message}`);
      } else {
        console.log(`‚úÖ Statement ${i + 1} executed successfully`);
      }
    }
    console.log('üéâ All SQL statements executed successfully');
    return {
      success: true,
      message: `Schema deployment completed: ${statements.length} statements executed`,
      statementsExecuted: statements.length
    };
  } catch (error) {
    console.error('‚ùå Schema deployment failed:', error);
    return {
      success: false,
      message: `Schema deployment failed: ${error.message}`,
      requiresManualDeployment: true
    };
  }
}
// Storage setup
async function setupStorage(targetClient, options) {
  console.log('üìÅ Setting up storage buckets...');
  try {
    // Simple storage setup - create basic buckets
    const buckets = [
      {
        id: 'documents',
        name: 'documents',
        public: false
      },
      {
        id: 'site-assets',
        name: 'site-assets',
        public: true
      }
    ];
    for (const bucket of buckets){
      try {
        const { error } = await targetClient.storage.createBucket(bucket.id, {
          public: bucket.public
        });
        if (error && !error.message.includes('already exists')) {
          console.log(`‚ö†Ô∏è Failed to create bucket ${bucket.id}: ${error.message}`);
        } else {
          console.log(`‚úÖ Bucket ${bucket.id} ready`);
        }
      } catch (bucketError) {
        console.log(`‚ö†Ô∏è Bucket ${bucket.id} setup issue`);
      }
    }
    return {
      success: true,
      message: 'Storage setup completed',
      bucketsConfigured: buckets.length
    };
  } catch (error) {
    return {
      success: false,
      message: `Storage setup failed: ${error.message}`
    };
  }
}
// Fresh Install Cleanup with Enhanced Safety
async function executeFreshInstallCleanup(targetClient, options) {
  console.log('üßπ Starting fresh install cleanup...');
  const cleanupOptions = options.options || {};
  const results = {
    tablesDropped: 0,
    functionsDropped: 0,
    policiesDropped: 0,
    bucketsDropped: 0,
    errors: [],
    preservedItems: []
  };
  try {
    // Step 1: Drop existing tables (with enhanced safety)
    if (cleanupOptions.dropExistingTables) {
      console.log('üóëÔ∏è Dropping existing tables...');
      // Get list of user tables using fallback method
      let tables = [];
      try {
        const { data, error } = await targetClient.rpc('get_public_tables');
        if (!error && data) {
          tables = data;
        }
      } catch (rpcError) {
        // Fallback: Get tables directly from information_schema
        console.log('üìã Using fallback method to get table list...');
        const { data, error } = await targetClient.from('information_schema.tables').select('table_name').eq('table_schema', 'public').neq('table_type', 'VIEW');
        if (!error && data) {
          tables = data.map((t)=>({
              table_name: t.table_name
            }));
        }
      }
      if (tables.length > 0) {
        // Define system tables to preserve
        const systemTables = cleanupOptions.preserveSystemTables ? [
          'site_settings',
          'user_roles',
          'profiles'
        ] : [];
        for (const table of tables){
          const tableName = table.table_name;
          // Skip system tables if preservation is enabled
          if (systemTables.includes(tableName)) {
            results.preservedItems.push(`table:${tableName}`);
            console.log(`üõ°Ô∏è Preserved system table: ${tableName}`);
            continue;
          }
          try {
            // Use direct SQL execution for better reliability
            const { error } = await targetClient.rpc('exec_sql', {
              sql: `DROP TABLE IF EXISTS public."${tableName}" CASCADE;`
            });
            if (!error) {
              results.tablesDropped++;
              console.log(`‚úÖ Dropped table: ${tableName}`);
            } else {
              results.errors.push(`Failed to drop table ${tableName}: ${error.message}`);
            }
          } catch (err) {
            results.errors.push(`Failed to drop table ${tableName}: ${err.message}`);
          }
        }
      } else {
        console.log('üì≠ No tables found to drop');
      }
    }
    // Step 2: Drop existing functions (with enhanced safety)
    if (cleanupOptions.dropExistingFunctions) {
      console.log('üóëÔ∏è Dropping existing functions...');
      let functions = [];
      try {
        const { data, error } = await targetClient.rpc('get_public_functions');
        if (!error && data) {
          functions = data;
        }
      } catch (rpcError) {
        console.log('üìã Functions cleanup skipped - RPC not available');
      }
      if (functions.length > 0) {
        for (const func of functions){
          try {
            const { error } = await targetClient.rpc('exec_sql', {
              sql: `DROP FUNCTION IF EXISTS public."${func.function_name}" CASCADE;`
            });
            if (!error) {
              results.functionsDropped++;
              console.log(`‚úÖ Dropped function: ${func.function_name}`);
            } else {
              results.errors.push(`Failed to drop function ${func.function_name}: ${error.message}`);
            }
          } catch (err) {
            results.errors.push(`Failed to drop function ${func.function_name}: ${err.message}`);
          }
        }
      } else {
        console.log('üì≠ No functions found to drop');
      }
    }
    // Step 3: Drop RLS policies (if specified)
    if (cleanupOptions.dropExistingPolicies) {
      console.log('üóëÔ∏è Dropping RLS policies...');
      try {
        // Drop all RLS policies in public schema
        const { error } = await targetClient.rpc('exec_sql', {
          sql: `
            DO $$ 
            DECLARE 
              pol record;
            BEGIN 
              FOR pol IN 
                SELECT schemaname, tablename, policyname 
                FROM pg_policies 
                WHERE schemaname = 'public'
              LOOP 
                EXECUTE format('DROP POLICY IF EXISTS %I ON %I.%I CASCADE', 
                              pol.policyname, pol.schemaname, pol.tablename);
              END LOOP;
            END $$;
          `
        });
        if (!error) {
          results.policiesDropped++;
          console.log(`‚úÖ Dropped RLS policies`);
        } else {
          results.errors.push(`Failed to drop policies: ${error.message}`);
        }
      } catch (err) {
        results.errors.push(`Failed to drop policies: ${err.message}`);
      }
    }
    // Step 4: Drop storage buckets (with caution)
    if (cleanupOptions.dropExistingBuckets) {
      console.log('üóëÔ∏è Dropping existing storage buckets...');
      try {
        const { data: buckets, error: listError } = await targetClient.storage.listBuckets();
        if (!listError && buckets) {
          for (const bucket of buckets){
            try {
              const { error } = await targetClient.storage.deleteBucket(bucket.id);
              if (!error) {
                results.bucketsDropped++;
                console.log(`‚úÖ Dropped bucket: ${bucket.id}`);
              } else {
                results.errors.push(`Failed to drop bucket ${bucket.id}: ${error.message}`);
              }
            } catch (err) {
              results.errors.push(`Failed to drop bucket ${bucket.id}: ${err.message}`);
            }
          }
        } else {
          console.log('üì≠ No buckets found or failed to list buckets');
        }
      } catch (err) {
        results.errors.push(`Failed to list/drop buckets: ${err.message}`);
      }
    }
    // Summary
    const summary = `Cleanup completed: ${results.tablesDropped} tables, ${results.functionsDropped} functions, ${results.bucketsDropped} buckets dropped`;
    console.log(`üéâ ${summary}`);
    if (results.preservedItems.length > 0) {
      console.log(`üõ°Ô∏è Preserved ${results.preservedItems.length} system items:`, results.preservedItems);
    }
    if (results.errors.length > 0) {
      console.log(`‚ö†Ô∏è ${results.errors.length} errors occurred during cleanup`);
    }
    return {
      success: true,
      message: summary,
      ...results
    };
  } catch (error) {
    console.error('‚ùå Cleanup failed:', error);
    return {
      success: false,
      message: `Cleanup failed: ${error.message}`,
      ...results
    };
  }
}
// Execute upgrade step
async function executeUpgradeStep(targetClient, options) {
  console.log('‚ö° Executing upgrade step...');
  const { sql, stepId } = options;
  if (!sql) {
    return {
      success: false,
      message: 'No SQL provided for step execution'
    };
  }
  try {
    const { error } = await targetClient.rpc('exec_sql', {
      sql
    });
    if (error) {
      throw new Error(error.message);
    }
    console.log(`‚úÖ Step ${stepId} executed successfully`);
    return {
      success: true,
      message: `Step ${stepId} executed successfully`,
      stepId
    };
  } catch (error) {
    console.error(`‚ùå Step ${stepId} failed:`, error);
    return {
      success: false,
      message: `Step ${stepId} failed: ${error.message}`,
      stepId
    };
  }
}
// Create backup
async function createBackup(targetClient, options) {
  console.log('üíæ Creating backup...');
  const backupId = `backup_${Date.now()}`;
  try {
    // In a real implementation, this would create a comprehensive backup
    // For now, we'll create a simple backup record
    const { error } = await targetClient.from('migration_backups').insert({
      backup_id: backupId,
      backup_type: options.backupType || 'pre-upgrade',
      created_at: new Date().toISOString(),
      status: 'completed'
    });
    if (error && !error.message.includes('does not exist')) {
      throw error;
    }
    console.log(`‚úÖ Backup created: ${backupId}`);
    return {
      success: true,
      message: `Backup created successfully`,
      backupId
    };
  } catch (error) {
    console.error('‚ùå Backup failed:', error);
    return {
      success: false,
      message: `Backup failed: ${error.message}`
    };
  }
}
// Execute rollback
async function executeRollback(targetClient, options) {
  console.log('üîÑ Executing rollback...');
  const { rollbackId } = options;
  try {
    // In a real implementation, this would restore from backup
    // For now, we'll just log the rollback attempt
    console.log(`üîÑ Rollback ${rollbackId} executed`);
    return {
      success: true,
      message: `Rollback ${rollbackId} executed successfully`
    };
  } catch (error) {
    console.error('‚ùå Rollback failed:', error);
    return {
      success: false,
      message: `Rollback failed: ${error.message}`
    };
  }
}
function extractProjectId(url) {
  const match = url.match(/https:\/\/([a-zA-Z0-9]+)\.supabase\.co/);
  return match ? match[1] : 'unknown';
}
